{
	"name": "Process PDF Files - Stage Zone",
	"properties": {
		"folder": {
			"name": "LecturaScripts"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spproymaestria",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "141ca457-875b-4cd2-8945-f69298640541"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/01c2d20c-2c85-4121-8018-3a801e74d84c/resourceGroups/ProyectoMaestria/providers/Microsoft.Synapse/workspaces/synapseproyectomaestria/bigDataPools/spproymaestria",
				"name": "spproymaestria",
				"type": "Spark",
				"endpoint": "https://synapseproyectomaestria.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spproymaestria",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"#Importando Librerias\r\n",
					"\r\n",
					"from pyspark.sql import SparkSession\r\n",
					"from io import BytesIO\r\n",
					"from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\r\n",
					"from pdfminer.pdfpage import PDFPage\r\n",
					"from pdfminer.converter import TextConverter\r\n",
					"from pdfminer.layout import LAParams\r\n",
					"import io\r\n",
					""
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Creando sesion \r\n",
					"\r\n",
					"spark = SparkSession.builder \\\r\n",
					"    .appName(\"PDF Extraction\") \\\r\n",
					"    .getOrCreate()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": [
						"parameters"
					]
				},
				"source": [
					"#Capturar Parametros\r\n",
					"pdf_user = \"\"\r\n",
					"pdf_type = \"\"\r\n",
					"pdf_fecha = \"\"\r\n",
					"pdf_file = \"\"\r\n",
					"pdf_password = \"\""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Consolidar Variables\r\n",
					"\r\n",
					"#Ruta Origen\r\n",
					"pdf_path_origin = \"abfss://stagefiles@datalakeproyectomaestria.dfs.core.windows.net/\"+pdf_user+\"/\"+pdf_type+\"/\"+pdf_fecha+\"/\"+pdf_file\r\n",
					"\r\n",
					"#Ruta Destino\r\n",
					"pdf_file = pdf_file.replace(\".pdf\", \".Parquet\")\r\n",
					"pdf_path_sink = \"abfss://stagedata@datalakeproyectomaestria.dfs.core.windows.net/\"+pdf_user+\"/\"+pdf_type+\"/\"+pdf_fecha"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Procesar informacion - Capturar informacion\r\n",
					"\r\n",
					"\r\n",
					"# Leer the PDF file como bytes\r\n",
					"pdf_bytes = spark.read \\\r\n",
					"    .format(\"binaryFile\") \\\r\n",
					"    .option(\"path\", pdf_path_origin) \\\r\n",
					"    .load() \\\r\n",
					"    .select(\"content\") \\\r\n",
					"    .collect()[0][0]\r\n",
					"\r\n",
					"# crear un BytesIO stream de the PDF bytes\r\n",
					"pdf_stream = BytesIO(pdf_bytes)\r\n",
					"pdf_stream.seek(0)\r\n",
					"\r\n",
					"# Crear objeto PDFResourceManager y configurar parametros\r\n",
					"rsrcmgr = PDFResourceManager()\r\n",
					"retstr = io.StringIO()\r\n",
					"\r\n",
					"# Crear Objeto  TextConverter para las paginas dle PDF\r\n",
					"laparams = LAParams()\r\n",
					"device = TextConverter(rsrcmgr, retstr, laparams=laparams)\r\n",
					"\r\n",
					"# Crear objeto PDFPageInterpreter\r\n",
					"interpreter = PDFPageInterpreter(rsrcmgr, device)\r\n",
					"\r\n",
					"# Porcesar cada pagina del archivo PDF\r\n",
					"password = pdf_password.encode()\r\n",
					"pages = PDFPage.get_pages(pdf_stream, password=password, check_extractable=True)\r\n",
					"for page in pages:\r\n",
					"    interpreter.process_page(page)\r\n",
					"\r\n",
					"# Obtener el texto extraido del objeto StringIO\r\n",
					"pdf_content = retstr.getvalue()\r\n",
					"\r\n",
					"# Cerrar el objeto StringIO\r\n",
					"device.close()\r\n",
					"retstr.close()"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print(pdf_content)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"tags": []
				},
				"source": [
					"# Generar un arcihvo con la data Cruda\r\n",
					"\r\n",
					"# Crear un dataframe con la informaicon extraida\r\n",
					"content_df = spark.createDataFrame([(pdf_content,)], [\"contenido\"])\r\n",
					"\r\n",
					"# Crear archivo  Parquet en el contendor\r\n",
					"content_df.write.option(\"spark.sql.sources.writeJobInfo.enabled\", \"false\").mode(\"overwrite\").parquet(pdf_path_sink)\r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}