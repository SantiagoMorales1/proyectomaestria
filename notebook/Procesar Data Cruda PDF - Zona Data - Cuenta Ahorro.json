{
	"name": "Procesar Data Cruda PDF - Zona Data - Cuenta Ahorro",
	"properties": {
		"folder": {
			"name": "LecturaScripts"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spproymaestria",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "b725aae1-2ec9-4ef3-b399-dd38f0f6ddd2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/01c2d20c-2c85-4121-8018-3a801e74d84c/resourceGroups/ProyectoMaestria/providers/Microsoft.Synapse/workspaces/synapseproyectomaestria/bigDataPools/spproymaestria",
				"name": "spproymaestria",
				"type": "Spark",
				"endpoint": "https://synapseproyectomaestria.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spproymaestria",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"#Importar Librerias Necesarias\r\n",
					"\r\n",
					"from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DoubleType\r\n",
					"from pyspark.sql.window import Window\r\n",
					"from pyspark.sql.functions import *"
				],
				"execution_count": 44
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Configurar parametros aqui\r\n",
					"\r\n",
					"user = \"bsmoralesg@outlook.com\"\r\n",
					"type = \"Cuenta Ahorros\"\r\n",
					"fecha = \"10012023\"\r\n",
					"\r\n",
					"#name = \"Extracto_49243429_202112_CTA_AHORROS_5557\"\r\n",
					"#name = \"Extracto_240056999_202209_CTA_AHORROS_5557\"\r\n",
					"#name = \"Extracto_307612445_202212_CTA_AHORROS_5557\"\r\n",
					"name = \"Extracto_375992443_202303_CTA_AHORROS_5557\""
				],
				"execution_count": 45
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Configurar rutas de origen y destino de archivos\r\n",
					"\r\n",
					"pathsource = \"abfss://stagedata@datalakeproyectomaestria.dfs.core.windows.net/\"+type+\"/Raw/\"+fecha+\"/\"+user+\"/\"+name"
				],
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Obtener Datos para Tarjeta Credito\r\n",
					"\r\n",
					"DataCruda = spark.read.load(pathsource+\"/*.parquet\", format='parquet')"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Dividir los valores por salto de linea\r\n",
					"\r\n",
					"df_split = DataCruda.withColumn(\"contenido\", split(DataCruda[\"contenido\"], \"\\n\"))\r\n",
					"\r\n",
					"# Transformar la columna array para crear una nueva fila por cada elemento\r\n",
					"df_formated = df_split.select(df_split.index, df_split.pagenumber, df_split.x0, df_split.x1, df_split.y0, df_split.y1, explode(\"contenido\").alias(\"contenido\"))\r\n",
					"\r\n",
					"#Crear identificador unico  basado enel orden de lectura\r\n",
					"\r\n",
					"Incremental = Window.orderBy(\"pagenumber\",\"index\")\r\n",
					"df_formated = df_formated.withColumn(\"UniqueId\", row_number().over(Incremental))"
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"display (df_formated)"
				],
				"execution_count": 49
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Obtener Informacion de Cliente\r\n",
					"\r\n",
					"Nombre = df_formated.select(df_formated.contenido).where((df_formated.UniqueId == 1)).first()[0]\r\n",
					"Email = user\r\n",
					"Direccion = df_formated.select(df_formated.contenido).where(df_formated.UniqueId == 3).first()[0]\r\n",
					"\r\n",
					"CiudadData = df_formated.select(df_formated.contenido).where(df_formated.UniqueId == 5).first()[0]\r\n",
					"CiudadData = CiudadData.replace(\"$\",\"\")\r\n",
					"CiudadData = CiudadData.replace(\"D.C.\",\"\")\r\n",
					"CiudadData = CiudadData.split(\"  \")\r\n",
					"\r\n",
					"CiudadData[0] = CiudadData[0].replace(\"BOGOTA\",\"BOGOTA D.C\")\r\n",
					"Ciudad_1 = CiudadData[0].strip()\r\n",
					"\r\n",
					"CiudadData[1] = CiudadData[1].replace(\"BOGOTA\",\"BOGOTA D.C\")\r\n",
					"Ciudad_2 = CiudadData[1].strip()\r\n",
					"\r\n",
					"# Crear dataframe para informacion de cliente\r\n",
					"\r\n",
					"schemaCliente = StructType([ \\\r\n",
					"    StructField(\"Nombre\",StringType(),True), \\\r\n",
					"    StructField(\"Email\",StringType(),True), \\\r\n",
					"    StructField(\"Direccion\",StringType(),True), \\\r\n",
					"    StructField(\"Ciudad_1\",StringType(),True), \\\r\n",
					"    StructField(\"Ciudad_2\", StringType(), True) \\\r\n",
					"  ])\r\n",
					"\r\n",
					"data_Cliente = [(Nombre, Email, Direccion, Ciudad_1, Ciudad_2)]\r\n",
					"\r\n",
					"df_Cliente = spark.createDataFrame(data=data_Cliente,schema=schemaCliente)"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Obtener Informacion de Prodcuto\r\n",
					"\r\n",
					"TipoProducto = 'Cuenta Ahorros'\r\n",
					"NumeroProducto = df_formated.select(df_formated.contenido).where(df_formated.UniqueId == 16).first()[0]\r\n",
					"Sucursal = df_formated.select(df_formated.contenido).where(df_formated.UniqueId == 14).first()[0]\r\n",
					"\r\n",
					"# Crear dataframe para informacion de producto\r\n",
					"\r\n",
					"schemaProducto = StructType([ \\\r\n",
					"    StructField(\"TipoProducto\",StringType(),True), \\\r\n",
					"    StructField(\"NumeroProducto\",StringType(),True), \\\r\n",
					"    StructField(\"Sucursal\",StringType(),True)\r\n",
					"  ])\r\n",
					"\r\n",
					"data_Producto = [(TipoProducto, NumeroProducto, Sucursal)]\r\n",
					"\r\n",
					"df_Producto = spark.createDataFrame(data=data_Producto,schema=schemaProducto)"
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Extraer informacion de transacciones\r\n",
					"\r\n",
					"# Definir incrementales basado en el uniqueid\r\n",
					"\r\n",
					"Incremental = Window.orderBy(\"UniqueId\")\r\n",
					"\r\n",
					"#Extraer Fecha de transacciones\r\n",
					"\r\n",
					"df_Fecha = df_formated.select(df_formated.contenido.alias(\"FechaTransaccion\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        ((df_formated.x0 >= 31.0) & (df_formated.x0 <= 32.0)) & \\\r\n",
					"        (df_formated.contenido != \"FECHA\")  & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"df_Fecha = df_Fecha.withColumn(\"id\", row_number().over(Incremental))\r\n",
					"\r\n",
					"# Obtener cantidad de transacciones\r\n",
					"CantidadTransacciones = df_Fecha.count()\r\n",
					"\r\n",
					"\r\n",
					"#Extraer descripcion transacciones\r\n",
					"\r\n",
					"df_Descripciones = df_formated.select(df_formated.contenido.alias(\"DescripcionTransaccion\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        ((df_formated.x0 >= 78.5) & (df_formated.x0 <= 81.0)) & \\\r\n",
					"        (df_formated.contenido != \"DESCRIPCIÃ“N\")  & \\\r\n",
					"        (df_formated.contenido != \"FIN ESTADO DE CUENTA\")  & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"df_Descripciones = df_Descripciones.withColumn(\"id\", row_number().over(Incremental))\r\n",
					"\r\n",
					"\r\n",
					"#Extraer sucursal\r\n",
					"\r\n",
					"df_Sucursal = df_formated.select(df_formated.contenido.alias(\"Sucursal\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        (df_formated.x0 == 269.516) & \\\r\n",
					"        (df_formated.contenido != \"SUCURSAL\")  & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"\r\n",
					"if (df_Sucursal.count() !=  CantidadTransacciones):\r\n",
					"    MaximaCantidadRegistros = df_Sucursal.count()\r\n",
					"    RegistrosPendintes = CantidadTransacciones - MaximaCantidadRegistros\r\n",
					"    MaxUniqueID = df_Sucursal.select(max(df_Sucursal.UniqueId)).first()[0]\r\n",
					"    \r\n",
					"    if MaxUniqueID is None:\r\n",
					"        MaxUniqueID = 1\r\n",
					"\r\n",
					"    for i in range (RegistrosPendintes):                \r\n",
					"        newRow = spark.createDataFrame([(\"\",str(MaxUniqueID+(i+1)))])\r\n",
					"        df_Sucursal = df_Sucursal.union(newRow)\r\n",
					"\r\n",
					"df_Sucursal = df_Sucursal.withColumn(\"id\", row_number().over(Incremental))\r\n",
					"\r\n",
					"\r\n",
					"#Extraer descuento\r\n",
					"\r\n",
					"df_Descuento = df_formated.select(df_formated.contenido.alias(\"Descuento\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        (df_formated.x0 == 355.095) & \\\r\n",
					"        (df_formated.contenido != \"DCTO.\")  & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"\r\n",
					"if (df_Descuento.count() !=  CantidadTransacciones):\r\n",
					"    MaximaCantidadRegistros = df_Descuento.count()\r\n",
					"    RegistrosPendintes = CantidadTransacciones - MaximaCantidadRegistros\r\n",
					"    MaxUniqueID = df_Descuento.select(max(df_Descuento.UniqueId)).first()[0]\r\n",
					"    \r\n",
					"    if MaxUniqueID is None:\r\n",
					"        MaxUniqueID = 1\r\n",
					"\r\n",
					"    for i in range (RegistrosPendintes):                \r\n",
					"        newRow = spark.createDataFrame([(\"\",str(MaxUniqueID+(i+1)))])\r\n",
					"        df_Descuento = df_Descuento.union(newRow)\r\n",
					"\r\n",
					"df_Descuento = df_Descuento.withColumn(\"id\", row_number().over(Incremental))\r\n",
					"\r\n",
					"\r\n",
					"# Extraer Valor Transaccion\r\n",
					"\r\n",
					"df_ValorTransaccion = df_formated.select(df_formated.contenido.alias(\"ValorTransaccion\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        ((df_formated.x1 >= 501.0) & (df_formated.x0 <= 502.0)) & \\\r\n",
					"        (df_formated.contenido.rlike(\"[0-9]\")) & \\\r\n",
					"        (~ df_formated.contenido.rlike(\"[a-z]\")) & \\\r\n",
					"        (~ df_formated.contenido.rlike(\"[A-Z]\")) & \\\r\n",
					"        (df_formated.contenido != \"VALOR\")  & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"df_ValorTransaccion = df_ValorTransaccion.withColumn(\"ValorTransaccion\", regexp_replace(df_ValorTransaccion.ValorTransaccion, ',', '')) \r\n",
					"df_ValorTransaccion = df_ValorTransaccion.withColumn(\"id\", row_number().over(Incremental))\r\n",
					"\r\n",
					"\r\n",
					"# Extraer Saldo\r\n",
					"\r\n",
					"df_Saldo = df_formated.select(df_formated.contenido.alias(\"Saldo\"), df_formated.UniqueId).where \\\r\n",
					"    ( \\\r\n",
					"        (((df_formated.x0 >= 533.0) & (df_formated.x0 <= 534.0)) | ((df_formated.x0 >= 549.0) & (df_formated.x0 <= 550.0)) | ((df_formated.x0 >= 539.0) & (df_formated.x0 <= 540.0))) & \\\r\n",
					"        (df_formated.contenido != \"SALDO\")  & \\\r\n",
					"        (df_formated.contenido.rlike(\"[0-9]\")) & \\\r\n",
					"        (df_formated.contenido != \"\")\r\n",
					"    )\r\n",
					"df_Saldo = df_Saldo.withColumn(\"Saldo\", regexp_replace(df_Saldo.Saldo, ',', '')) \r\n",
					"df_Saldo = df_Saldo.withColumn(\"id\", row_number().over(Incremental))\r\n",
					""
				],
				"execution_count": 52
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#df_Fecha.show(200)\r\n",
					"#df_Sucursal.show(200)\r\n",
					"#df_Descuento.show(200)\r\n",
					"#df_ValorTransaccion.show(200)\r\n",
					"#df_Saldo.show(200)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"df_Transacciones = df_Fecha.join(df_Descripciones, df_Fecha.id == df_Descripciones.id, \"inner\") \\\r\n",
					"                  .join(df_Sucursal , df_Fecha.id == df_Sucursal.id, \"inner\") \\\r\n",
					"                  .join(df_Descuento, df_Fecha.id == df_Descuento.id, \"inner\") \\\r\n",
					"                  .join(df_ValorTransaccion, df_Fecha.id == df_ValorTransaccion.id, \"inner\") \\\r\n",
					"                  .join(df_Saldo, df_Fecha.id == df_Saldo.id, \"inner\") \\\r\n",
					"                  .select( \\\r\n",
					"                        df_Fecha.FechaTransaccion, \\\r\n",
					"                        df_Descripciones.DescripcionTransaccion, \\\r\n",
					"                        df_Sucursal.Sucursal, \\\r\n",
					"                        df_Descuento.Descuento, \\\r\n",
					"                        df_ValorTransaccion.ValorTransaccion, \\\r\n",
					"                        df_Saldo.Saldo            \r\n",
					"                        )"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"#display(df_Cliente)\r\n",
					"#display(df_Producto)\r\n",
					"#display(df_Transacciones)"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Generar archivos con informacion\r\n",
					"\r\n",
					"Routeadl = \"abfss://stagedata@datalakeproyectomaestria.dfs.core.windows.net\"\r\n",
					"path_sink_comp = fecha+\"/\"+user+\"/\"+name\r\n",
					"\r\n",
					"# crear parquet file para cliente\r\n",
					"df_Cliente.write.mode(\"overwrite\").parquet(Routeadl+\"/\"+type+\"/Cliente/\"+path_sink_comp)\r\n",
					"\r\n",
					"# crear parquet file para porducto\r\n",
					"df_Producto.write.mode(\"overwrite\").parquet(Routeadl+\"/\"+type+\"/Producto/\"+path_sink_comp)\r\n",
					"\r\n",
					"# crear parquet file para transacciones\r\n",
					"df_Transacciones.write.mode(\"overwrite\").parquet(Routeadl+\"/\"+type+\"/Transacciones/\"+path_sink_comp)\r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}